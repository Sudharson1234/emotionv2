<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection - Video</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> <!-- Chart.js for bar chart -->
    <style>
        body {
          background: linear-gradient(to right, #48849e, #325d6b, #244c5e);
          color: #fff;
          font-family: 'Poppins', sans-serif;
        }
    
        .container {
          max-width: 720px;
          margin-top: 3rem;
        }
    
        .card {
          background: rgba(5, 5, 5, 0.584);
          backdrop-filter: blur(10px);
          border-radius: 16px;
          box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
          color: white;
          padding: 1.5rem;
        }
    
        .form-control {
          background: rgba(255, 255, 255, 0.2);
          border: none;
          color: #fff;
        }
    
        .btn {
          font-size: 0.9rem;
          padding: 8px 20px;
          border-radius: 8px;
          margin: 0.3rem;
        }
    
        .btn-primary {
          background: linear-gradient(135deg, #00c6ff, #0072ff);
          border: none;
        }
    
        .btn-secondary {
          background-color: #444;
          border: none;
        }
    
        .btn-success, .btn-danger {
          width: 48%;
        }
    
        h2, h3, h4 {
          font-weight: 600;
        }
    
        video {
          max-width: 100%;
          border-radius: 8px;
          margin-top: 0.5rem;
        }
    
        #result {
          font-size: 1.1rem;
          font-weight: 500;
        }
    
        canvas {
          margin-top: 1rem;
        }
      </style>
</head>

<body>
    <nav class="navbar navbar-dark bg-dark shadow-sm px-4">
        <span class="navbar-text fw-semibold text-white">üîµ Emotion Detection</span>
        <div class="ms-auto">
          <a class="nav-link text-white fw-semibold" href="/userpage">Profile</a>
        </div>
      </nav>
      
    <div class="container">
        <h2 class="text-center mb-4">Video Emotion Detection</h2>
        <div class="card mx-auto">
            <!-- Toggle Between Upload & Camera -->
            <div class="text-center mb-3">
                <button id="toggleBtn" class="btn btn-secondary">Use Camera</button>
            </div>

            <!-- Video Upload Form -->
            <form id="uploadForm" enctype="multipart/form-data">
                <div class="mb-3" id="uploadSection">
                    <input type="file" class="form-control" id="fileInput" name="file" accept="video/*">
                </div>
                <button type="submit" id="analyzeUpload" class="btn btn-primary w-100">Analyze</button>
            </form>

            <div id="uploadedPreviewSection" class="mt-3 text-center" style="display: none;">
                <h4 style="color: #00adb5;">Uploaded Video</h4>
                <video id="uploadedVideo" width="50%" height="auto" controls></video>
            </div>

            <!-- Camera Recording Section -->
            <div id="cameraSection" class="text-center" style="display: none;">
                <video id="video" width="100%" height="auto" autoplay></video>
                <div class="mt-2">
                    <p id="detectedEmotion" style="color: #00adb5; font-weight: bold;">Face Emotion: --</p>
                </div>
                <button id="startRecording" class="btn btn-success mt-2">Start Recording</button>
                <button id="stopRecording" class="btn btn-danger mt-2" style="display: none;">Stop Recording</button>
                <button id="toggleLiveChat" class="btn btn-info mt-2" style="display: none;">üí¨ Live Chat</button>
            </div>

            <!-- Video Preview -->
            <div id="previewSection" class="mt-3 text-center" style="display: none;">
                <h3 style="color: #008b8b;">Recorded Video</h3>
                <video id="recordedVideo" width="50%" height="auto" controls></video>
                <button id="detectEmotion" class="btn btn-primary mt-2 w-100">Analyze Emotion</button>
            </div>

            <!-- Result -->
            <div id="result" class="mt-4 text-center"></div>
            <div class="mt-4">
                <canvas id="emotionChart"></canvas>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        const toggleBtn = document.getElementById("toggleBtn");
        const uploadSection = document.getElementById("uploadSection");
        const uploadedPreviewSection = document.getElementById("uploadedPreviewSection");
        const uploadedVideo = document.getElementById("uploadedVideo");
        const cameraSection = document.getElementById("cameraSection");
        const previewSection = document.getElementById("previewSection");
        const video = document.getElementById("video");
        const recordedVideo = document.getElementById("recordedVideo");
        const startRecording = document.getElementById("startRecording");
        const stopRecording = document.getElementById("stopRecording");
        const detectEmotion = document.getElementById("detectEmotion");
        const analyzeUpload = document.getElementById("analyzeUpload");
        const toggleLiveChat = document.getElementById("toggleLiveChat");
        const detectedEmotionDisplay = document.getElementById("detectedEmotion");
        const resultDiv = document.getElementById("result");
        let emotionChart;
        let interval;
        let mediaRecorder;
        let recordedChunks = [];
        let useCamera = false;

        document.getElementById("fileInput").addEventListener("change",function(){
            const file = this.files[0];
            if(file){
                const videoURL = URL.createObjectURL(file);
                uploadedVideo.src = videoURL;
                uploadedPreviewSection.style.display= "block";
            }else{
                uploadedVideo.src = "";
                uploadedPreviewSection.style.display = "none";
            }
        })

        // Toggle between video upload & camera recording
        toggleBtn.addEventListener("click", function () {
            useCamera = !useCamera;
            if (useCamera) {
                uploadSection.style.display = "none";
                cameraSection.style.display = "block";
                previewSection.style.display = "none";
                toggleBtn.textContent = "Use Upload";
                analyzeUpload.style.display = "none";
                uploadedPreviewSection.style.display = "none";
                startCamera();
            } else {
                uploadSection.style.display = "block";
                cameraSection.style.display = "none";
                previewSection.style.display = "none";
                toggleBtn.textContent = "Use Camera";
                analyzeUpload.style.display = "block";
                stopCamera();
            }
            resultDiv.innerHTML = "";
                resetChart()
        });

        // Start Camera with face detection
        function startCamera() {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                })
                .catch(err => console.error("Error accessing camera:", err));
        }

        // Stop Camera
        function stopCamera() {
            cameraSection.style.display = "none";
            let stream = video.srcObject;
            if (stream) {
                let tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
            }
            video.srcObject = null;
        }

        // Start Recording
        startRecording.addEventListener("click", function () {
            recordedChunks = [];
            let stream = video.srcObject;
            mediaRecorder = new MediaRecorder(stream, { mimeType: "video/webm" });

            mediaRecorder.ondataavailable = event => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: "video/webm" });
                const url = URL.createObjectURL(blob);
                recordedVideo.src = url;
                previewSection.style.display = "block";
                startRecording.style.display = "inline-block";
                stopRecording.style.display = "none";
                toggleLiveChat.style.display = "inline-block";
            };

            mediaRecorder.start();
            startRecording.style.display = "none";
            stopRecording.style.display = "inline-block";
        });

        // Stop Recording
        stopRecording.addEventListener("click", function () {
            mediaRecorder.stop();
        });

        // Toggle Live Chat during camera stream
        toggleLiveChat.addEventListener("click", function() {
            openLiveChatModal();
        });

        // Upload Recorded Video for Emotion Analysis
        detectEmotion.addEventListener("click", function () {
            const blob = new Blob(recordedChunks, { type: "video/webm" });
            const formData = new FormData();
            formData.append("file", blob, "recorded_video.webm");

            document.getElementById("result").innerHTML = `Analyzing emotions...`;

            // Start Dynamic Bar Chart Updates
            if (!emotionChart) {
                initializeChart();
            }
            interval = setInterval(() => updateChart(true), 500);

            fetch("/video_upload", {
                method: "POST",
                body: formData
            })
                .then(response => response.json())
                .then(data => {
                    console.log("Server Response:", data);
                    displayResult(data)

                    if (data.error) {
                        document.getElementById("result").innerHTML = `<p class='text-danger'>Error: ${data.error}</p>`;
                    } else if (data.most_common_emotion) {
                        let emotionList = "<ul class='text-success'>";
                        for (const [emotion, count] of Object.entries(data.emotion_counts)) {
                            emotionList += `<li><strong>${emotion}:</strong> ${count}</li>`;
                        }
                        emotionList += "</ul>";

                        document.getElementById("result").innerHTML = `
        <p class='text-success'><strong>Detected Emotion:</strong> ${data.most_common_emotion}</p>
    `;

                    } else {
                        document.getElementById("result").innerHTML = `<p class='text-warning'>‚ö†Ô∏è No emotion detected.</p>`;
                    }
                })
                .catch(error => {
                    console.error("Fetch error:", error);
                    document.getElementById("result").innerHTML = `<p class='text-danger'>Error analyzing video.</p>`;
                    clearInterval(interval)
                });
        });

        function openLiveChatModal() {
            // This function would open the live chat modal/window
            // For now, just show a message that they can enable live chat
            alert('Live Chat is ready! The AI will respond based on your detected facial emotions.');
            // In a full implementation, you would open a modal or navigate to live chat
        }

        function initializeChart() {
            const ctx = document.getElementById("emotionChart").getContext("2d");
            emotionChart = new Chart(ctx, {
                type: "bar",
                data: {
                    labels: ["Happy", "Sad", "Angry", "Neutral", "Surprise", "Fear"],
                    datasets: [{
                        label: "Emotion Intensity",
                        backgroundColor: ["#FFD700", "#3498db", "#e74c3c", "#95a5a6", "#f39c12", "#8e44ad"],
                        borderWidth: 1,
                        data: [0, 0, 0, 0, 0, 0]
                    }]
                },
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 30
                        }
                    }
                }
            });
        }

        function updateChart(fake = true, realData = null) {
            if (!emotionChart) return;

            if (fake) {
                emotionChart.data.datasets[0].data = emotionChart.data.datasets[0].data.map(() => Math.floor(Math.random() * 100));
            } else if (realData) {
                emotionChart.data.datasets[0].data = [
                    realData["Happy"] || 0,
                    realData["Sad"] || 0,
                    realData["Angry"] || 0,
                    realData["Neutral"] || 0,
                    realData["Surprise"] || 0,
                    realData["Fear"] || 0
                ];
            }
            emotionChart.update();
        }

        document.getElementById("uploadForm").addEventListener("submit", async function (event) {
            event.preventDefault();

            let fileInput = document.getElementById("fileInput").files[0];
            if (!fileInput) {
                document.getElementById("result").innerHTML = `<p class='text-danger'>‚ö†Ô∏è Please select a video file.</p>`;
                return;
            }

            let formData = new FormData();
            formData.append("file", fileInput);

            document.getElementById("result").innerHTML = "<p class='text-warning'>Analyzing emotions...</p>";
            if (!emotionChart) {
                initializeChart();
            }
            interval = setInterval(() => updateChart(true), 500);
            try {
                let response = await fetch("/video_upload", {
                    method: "POST",
                    body: formData
                });

                let data = await response.json();
                displayResult(data);
            } catch (error) {
                console.error("Error:", error);
                document.getElementById("result").innerHTML = `<p class='text-danger'>Error analyzing video.</p>`;
                clearInterval(interval);
            }
        });

        function normalizeKeys(obj) {
            const normalized = {};
            for (const [key, value] of Object.entries(obj)) {
                const capitalized = key.charAt(0).toUpperCase() + key.slice(1).toLowerCase();
                normalized[capitalized] = value;
            }
            return normalized;
        }

        function displayResult(data) {
            clearInterval(interval);

            if (data.error) {
                resultDiv.innerHTML = `<p class='text-danger'>Error: ${data.error}</p>`;
            } else if (data.most_common_emotion) {
                let emotionList = "<ul class='text-success'>";
                for (const [emotion, count] of Object.entries(data.emotion_counts)) {
                    emotionList += `<li><strong>${emotion}:</strong> ${count}</li>`;
                }
                emotionList += "</ul>";
                resultDiv.innerHTML = `
                    <p class='text-success'><strong>Detected Emotion:</strong> ${data.most_common_emotion}</p>
                `;

                const normalizedData = normalizeKeys(data.emotion_counts);
                updateChart(false, normalizedData);
            } else {
                resultDiv.innerHTML = `<p class='text-warning'>‚ö†Ô∏è No emotion detected.</p>`;
            }
        }

        function resetChart() {
            if (emotionChart) {
                emotionChart.destroy();
                emotionChart = null;
            }
        }
    </script>
</body>

</html>